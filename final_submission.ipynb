{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOxYcP1R-zjm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import zipfile\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.utils import resample\n",
    "# import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code can achieve our best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcSKX8pt-4Aa"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "def import_data_from_csv():\n",
    "    df_train = pd.read_csv('train_data.csv')\n",
    "    df_test = pd.read_csv('test_data.csv')\n",
    "    return df_train, df_test\n",
    "train_data, test_data = import_data_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r70iMQ4Q_c9t"
   },
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "train_data['LastTaskCompleted'].fillna('Not_Saved', inplace=True)\n",
    "train_data['CurrentTask'].fillna('Not_Playing', inplace=True)\n",
    "train_data['LevelProgressionAmount'].fillna(0, inplace=True)\n",
    "\n",
    "test_data['LastTaskCompleted'].fillna('Not_Saved', inplace=True)\n",
    "test_data['CurrentTask'].fillna('Not_Playing', inplace=True)\n",
    "test_data['LevelProgressionAmount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8hiCnmA_rNN"
   },
   "outputs": [],
   "source": [
    "# Remove outliers from training data\n",
    "def remove_outliers(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "train_data = remove_outliers(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OkLckrb_9Qp"
   },
   "outputs": [],
   "source": [
    "# 'TimeUtc': According to feature \"TimeUtc\", we extract the date and time information and create two new features \"Day\" and \"Time\"\n",
    "# \"Day\" should be a categorical feature and include monday, tuesday, wednesday, thursday, friday, saturday, and sunday, and then it gets encoded\n",
    "# \"Time\" should be a categorical feature and include night, daytime, and evening, and then it gets encoded\n",
    "train_data['TimeUtc'] = pd.to_datetime(train_data['TimeUtc'])\n",
    "train_data['Day'] = train_data['TimeUtc'].dt.day_name()\n",
    "# train_data_1['Day'] = pd.Categorical(train_data_1['Day'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "train_data['Time'] = train_data['TimeUtc'].dt.hour\n",
    "train_data['Time'] = pd.cut(train_data['Time'], bins=[-1, 5, 17, 23], labels=['night', 'daytime', 'evening'])\n",
    "# encode 'Day': Monday=0, Tuesday=1, Wednesday=2, Thursday=3, Friday=4, Saturday=5, Sunday=6\n",
    "train_data['Day'] = train_data['Day'].map({'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6})\n",
    "train_data['Time'] = train_data['Time'].map({'night': 0, 'daytime': 1, 'evening': 2})\n",
    "# change 'Day' and 'Time' to int\n",
    "train_data['Day'] = train_data['Day'].astype(int)\n",
    "train_data['Time'] = train_data['Time'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTtabe0TADGC"
   },
   "outputs": [],
   "source": [
    "test_data['TimeUtc'] = pd.to_datetime(test_data['TimeUtc'])\n",
    "test_data['Day'] = test_data['TimeUtc'].dt.day_name()\n",
    "\n",
    "test_data['Time'] = test_data['TimeUtc'].dt.hour\n",
    "test_data['Time'] = pd.cut(test_data['Time'], bins=[-1, 5, 17, 23], labels=['night', 'daytime', 'evening'])\n",
    "\n",
    "test_data['Day'] = test_data['Day'].map({'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6})\n",
    "test_data['Time'] = test_data['Time'].map({'night': 0, 'daytime': 1, 'evening': 2})\n",
    "\n",
    "test_data['Day'] = test_data['Day'].astype(int)\n",
    "test_data['Time'] = test_data['Time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9BE-CueAloX"
   },
   "outputs": [],
   "source": [
    "# Standardize the numerical feature\n",
    "scaler = StandardScaler()\n",
    "train_data[['Day', 'Time', 'CurrentSessionLength']] = scaler.fit_transform(train_data[['Day', 'Time', 'CurrentSessionLength']])\n",
    "test_data[['Day', 'Time', 'CurrentSessionLength']] = scaler.fit_transform(test_data[['Day', 'Time', 'CurrentSessionLength']])\n",
    "\n",
    "train_data['StandardizedProgression'] = scaler.fit_transform(train_data[['LevelProgressionAmount']])\n",
    "test_data['StandardizedProgression'] = scaler.fit_transform(test_data[['LevelProgressionAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ob3eMk8YA3r4"
   },
   "outputs": [],
   "source": [
    "# Group by 'UserID' and calculate statistical features for 'ResponseValue'\n",
    "user_stats = train_data.groupby('UserID')['ResponseValue'].agg(['mean', 'median', 'std']).reset_index()\n",
    "user_stats.columns = ['UserID', 'ResponseValue_mean', 'ResponseValue_median', 'ResponseValue_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0i1W_xl8A7e7"
   },
   "outputs": [],
   "source": [
    "# Merge the new features back into the original dataframe\n",
    "train_data = pd.merge(train_data, user_stats, on='UserID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dcwz4UsBACP"
   },
   "outputs": [],
   "source": [
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['ResponseValue_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbBzPUpCBI2f"
   },
   "outputs": [],
   "source": [
    "train_data['UserID'] = train_data['UserID'].str.replace('p', '').astype(int)\n",
    "test_data['UserID'] = test_data['UserID'].str.replace('p', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgxpPAM-BNsO"
   },
   "outputs": [],
   "source": [
    "# Apply categorization to LastTaskCompleted and CurrentTask\n",
    "special_tasks = [\n",
    "    'MarsRover', 'MARS_MARSROVER', 'WASH_MarsRover', 'RECREATIONGROUND_MINIGOLF', 'SteamLocomotive',\n",
    "    'WASH_SteamLocomotive', 'DESERT_STEAMLOCOMOTIVE', 'WASH_Fountain','RECREATIONGROUND_FOUNTAIN'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SLLXgdUBOwd"
   },
   "outputs": [],
   "source": [
    "def categorize_task(task):\n",
    "\n",
    "    if task == 'Not_Saved' or task == 'Not_Playing':\n",
    "        return 0\n",
    "    elif task in special_tasks:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPPpJRUFBVg3",
    "outputId": "80fd846f-300d-416c-e685-ae12330b8398"
   },
   "outputs": [],
   "source": [
    "train_data['LastTaskCompleted_Category'] = train_data['LastTaskCompleted'].apply(categorize_task)\n",
    "train_data['CurrentTask_Category'] = train_data['CurrentTask'].apply(categorize_task)\n",
    "\n",
    "test_data['LastTaskCompleted_Category'] = test_data['LastTaskCompleted'].apply(categorize_task)\n",
    "test_data['CurrentTask_Category'] = test_data['CurrentTask'].apply(categorize_task)\n",
    "\n",
    "# Verify the results\n",
    "print(train_data[['LastTaskCompleted', 'CurrentTask', 'LastTaskCompleted_Category', 'CurrentTask_Category']].head())\n",
    "\n",
    "print(test_data[['LastTaskCompleted', 'CurrentTask', 'LastTaskCompleted_Category', 'CurrentTask_Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9Ze_ksDDUTX"
   },
   "outputs": [],
   "source": [
    "# Group by 'UserID' and calculate statistical features for 'CurrentSessionLength' and 'LevelProgressionAmount'\n",
    "CSLstats = train_data.groupby('UserID')['CurrentSessionLength'].agg(['mean', 'median', 'std', 'max']).reset_index()\n",
    "CSLstats.columns = ['UserID', 'CSL_mean', 'CSL_median', 'CSL_std', 'CSL_max']\n",
    "LPAstats = train_data.groupby('UserID')['LevelProgressionAmount'].agg(['mean', 'median', 'std', 'max']).reset_index()\n",
    "LPAstats.columns = ['UserID', 'LPA_mean', 'LPA_median', 'LPA_std', 'LPA_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeQVro6JDcDx"
   },
   "outputs": [],
   "source": [
    "# Merge the new features back into the original dataframe\n",
    "train_data = pd.merge(train_data, CSLstats, on='UserID', how='left')\n",
    "train_data = pd.merge(train_data, LPAstats, on='UserID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZP_IeMfBFQV4"
   },
   "outputs": [],
   "source": [
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['CSL_std'].fillna(0, inplace=True)\n",
    "\n",
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['LPA_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkj57QjLF-FJ"
   },
   "outputs": [],
   "source": [
    "# Filter out ResponseValue with only one instance\n",
    "value_counts = train_data['ResponseValue'].value_counts()\n",
    "filtered_train_data = train_data[train_data['ResponseValue'].isin(value_counts[value_counts > 1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFdBj2laIWPB"
   },
   "outputs": [],
   "source": [
    "# give test_data a new feature 'index'\n",
    "test_data['index'] = test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyYeIFsvNkdO"
   },
   "outputs": [],
   "source": [
    "# Selecting data\n",
    "# Identify the unique users in the training set and test set\n",
    "train_users = train_data['UserID'].unique()\n",
    "test_users = test_data['UserID'].unique()\n",
    "\n",
    "# Find the users in the test set that are not in the training set\n",
    "new_users = set(test_users) - set(train_users)\n",
    "new_users = list(new_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkiEoh-skadL",
    "outputId": "8e88fea0-10ac-45a7-f944-ac5b8228d4ae"
   },
   "outputs": [],
   "source": [
    " #Filter the test data to get the rows corresponding to these new users\n",
    "new_users_data = test_data[test_data['UserID'].isin(new_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGlsrUIaHk8l",
    "outputId": "9133645e-61d2-4015-fd8e-2658427522ae"
   },
   "outputs": [],
   "source": [
    "# Find the users that are present in both the training and test sets\n",
    "shared_users = set(train_users).intersection(set(test_users))\n",
    "shared_users = list(shared_users)\n",
    "\n",
    "# Filter the test data to get the rows corresponding to these shared users\n",
    "shared_users_data = test_data[test_data['UserID'].isin(shared_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfnbfpvCIWPJ"
   },
   "outputs": [],
   "source": [
    "# select the feature 'index' out of the new_users_data and shared_users_data\n",
    "new_users_data_index = new_users_data['index']\n",
    "shared_users_data_index = shared_users_data['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhx_rNKcIvZg"
   },
   "outputs": [],
   "source": [
    "# Calculate historical features from the training data\n",
    "train_user_stats = train_data.groupby('UserID')['ResponseValue'].agg([\n",
    "    'mean',\n",
    "    'median',\n",
    "    'std',\n",
    "    'min',\n",
    "    'max',\n",
    "    'count'\n",
    "]).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "train_user_stats.columns = [\n",
    "    'UserID',\n",
    "    'ResponseValue_mean',\n",
    "    'ResponseValue_median',\n",
    "    'ResponseValue_std',\n",
    "    'ResponseValue_min',\n",
    "    'ResponseValue_max',\n",
    "    'ResponseValue_count'\n",
    "]\n",
    "\n",
    "# Merge historical statistics into the shared_users_data test set\n",
    "shared_users_data = pd.merge(shared_users_data, train_user_stats, on='UserID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ua3KPUQMKX4a"
   },
   "outputs": [],
   "source": [
    "# Prepare features and target variable for training\n",
    "target = 'ResponseValue'\n",
    "features = [\n",
    "    'CurrentSessionLength', 'Day', 'Time', 'StandardizedProgression',\n",
    "    'ResponseValue_mean', 'ResponseValue_median', 'ResponseValue_std']\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H39Lo6PyKYrn"
   },
   "outputs": [],
   "source": [
    "# Prepare features for the test set\n",
    "X_test = shared_users_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 500],\n",
    "    'depth': [4, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "cat_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=cat_model, param_grid=param_grid, cv=skf, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MAE: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCWWFeUzIWPK"
   },
   "outputs": [],
   "source": [
    "# Define the CatBoost model with specified parameters and specify a directory for temporary files\n",
    "model = CatBoostRegressor(iterations=500,\n",
    "                          learning_rate=0.1,\n",
    "                          depth=10,\n",
    "                          loss_function='MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPxijhjQPoRX",
    "outputId": "b72f1c37-09b1-4d3d-f6e0-56604b5cf480"
   },
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10\n",
    "cross_validator = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and calculate negative mean absolute error (MAE)\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=cross_validator, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Convert negative MAE scores to positive\n",
    "positive_cv_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validation scores and average MAE\n",
    "print(f'Cross-validation MAE scores: {positive_cv_scores}')\n",
    "print(f'Average MAE: {positive_cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pknk3P82VLq6",
    "outputId": "bbc0765d-88c5-4c9f-e578-3b4e1cf358a0"
   },
   "outputs": [],
   "source": [
    "#final model on the entire training dataset\n",
    "final_model = model.fit(X_train, y_train)\n",
    "\n",
    "# predictions on the test dataset\n",
    "predictions = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9D4HzRxGIWPK"
   },
   "outputs": [],
   "source": [
    "shared_users_data['Predicted_ResponseValue'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxZqdehMIWPL"
   },
   "outputs": [],
   "source": [
    "shared_users_prediction = shared_users_data[['index', 'Predicted_ResponseValue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODeh-gTpLXA_"
   },
   "outputs": [],
   "source": [
    "# Calculate the mean predicted response value for shared users\n",
    "mean_predicted_response = shared_users_data['Predicted_ResponseValue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAfV9xC2IWPM",
    "outputId": "a4998371-b4c1-4db1-de41-3235cabc591d"
   },
   "outputs": [],
   "source": [
    "mean_predicted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrXyJdnIc2GR"
   },
   "outputs": [],
   "source": [
    "# Ensure no SettingWithCopyWarning by explicitly making a copy of the DataFrame slice\n",
    "new_users_data_1 = new_users_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7h88_jsIWPM"
   },
   "outputs": [],
   "source": [
    "new_users_data_1['Predicted_ResponseValue'] = mean_predicted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ibVfTq_IWPN"
   },
   "outputs": [],
   "source": [
    "new_users_prediction = new_users_data_1[['index', 'Predicted_ResponseValue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpan4e5gIWPN"
   },
   "outputs": [],
   "source": [
    "# concatenate the predictions for the new users and shared users\n",
    "final_predictions = pd.concat([shared_users_prediction, new_users_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "os6jrPpyIWPO"
   },
   "outputs": [],
   "source": [
    "# sort the final predictions by the index\n",
    "final_predictions_sorted = final_predictions.sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyrGxTr-IWPO"
   },
   "outputs": [],
   "source": [
    "# only keep the 'Predicted_ResponseValue' column\n",
    "final_predictions_sorted_ResponseValue = final_predictions_sorted['Predicted_ResponseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_predictions_sorted_ResponseValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predictions to a CSV file, but delete the column name\n",
    "final_predictions_sorted_ResponseValue.to_csv('predicted.csv', index=False, header=False)\n",
    "\n",
    "with zipfile.ZipFile('predicted.zip', 'w') as z:\n",
    "    z.write('predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code is used for other ways of data cleaning, EDA, feature engineering, modeling, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "def import_data_from_csv():\n",
    "    df_train = pd.read_csv('train_data.csv')\n",
    "    df_test = pd.read_csv('test_data.csv')\n",
    "    return df_train, df_test\n",
    "train_data, test_data = import_data_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. UserID\n",
    "train_data['UserID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. QuestionTiming\n",
    "train_data['QuestionTiming'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. TimeUtc\n",
    "train_data[\"TimeUtc\"] = pd.to_datetime(train_data[\"TimeUtc\"])\n",
    "\n",
    "# Find the earliest date\n",
    "earliest_date = train_data[\"TimeUtc\"].min()\n",
    "\n",
    "# Find the most recent date\n",
    "recent_date = train_data[\"TimeUtc\"].max()\n",
    "\n",
    "print(\"Earliest Date:\", earliest_date)\n",
    "print(\"Most Recent Date:\", recent_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract workday and weekend\n",
    "train_data['Day'] = train_data['TimeUtc'].dt.day_name()\n",
    "train_data['Day'] = train_data['Day'].map({'Monday': 'Workday', 'Tuesday': 'Workday', 'Wednesday': 'Workday', 'Thursday': 'Workday', 'Friday': 'Workday', 'Saturday': 'Weekend', 'Sunday': 'Weekend'})\n",
    "\n",
    "# extract the hour of the day\n",
    "train_data['Hour'] = train_data['TimeUtc'].dt.hour\n",
    "\n",
    "# plot the distribution of Day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='Day')\n",
    "plt.title('Distribution of Day')\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of Hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='Hour')\n",
    "plt.title('Distribution of Hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract workday and weekend\n",
    "train_data['Day'] = train_data['TimeUtc'].dt.day_name()\n",
    "\n",
    "# extract the hour of the day\n",
    "train_data['Hour'] = train_data['TimeUtc'].dt.hour\n",
    "\n",
    "# change Hour into three categories: night, daytime, and evening\n",
    "train_data['Hour'] = pd.cut(train_data['Hour'], bins=[-1, 5, 17, 23], labels=['night', 'daytime', 'evening'])\n",
    "\n",
    "# plot the distribution of Day\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='Day')\n",
    "plt.title('Distribution of Day')\n",
    "plt.show()\n",
    "\n",
    "# plot the distribution of Hour\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='Hour')\n",
    "plt.title('Distribution of Hour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CurrentGameMode\n",
    "# plot the distribution of CurrentGameMode\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='CurrentGameMode')\n",
    "plt.title('Distribution of CurrentGameMode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CurrentTask\n",
    "# plot the distribution of CurrentTask\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='CurrentTask')\n",
    "plt.title('Distribution of CurrentTask')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize CurrentTask\n",
    "def categorize_current_task(task):\n",
    "    vehicles = ['CAR', 'MOTORBIKE', 'BICYCLE', 'VINTAGECAR', 'FIRETRUCK', 'SUBMARINE', 'UFO', 'PLANE', 'HELICOPTER', 'TRAIN', 'LOCOMOTIVE',\n",
    "                 'PWVan', 'DirtBike', 'GolfCart', 'MotorbikeSidecar', '80sRacingCar', 'FireTruck', 'CamperVan', 'PrivateJet', 'MarsRover',\n",
    "                 'SUV', 'FireHelicopter', 'FortuneTellerCaravan', 'MonsterTruck', 'StuntPlane', 'SteamLocomotive', 'HOME_VAN', 'SUBURBIA_CAMPERVAN',\n",
    "                 'HOME_DIRTBIKE', 'HOME_GOLFCART', 'SUBURBIA_VINTAGECAR', 'HANGAR_STUNTPLANE', 'HOME_SUV', 'HANGAR_MONSTERTRUCK',\n",
    "                 'HOME_MOTORBIKESIDECAR', 'MARS_MARSROVER', 'MARINA_FISHINGBOAT', 'DESERT_UFO', 'WATER_HOME_VAN', 'TIME_HOME_MOTORBIKESIDECAR',\n",
    "                 'WATER_HOME_GOLFCART', 'TIME_HOME_VAN', 'TIME_HOME_DIRTBIKE', 'WATER_FIRESTATION_FIRETRUCK', 'HOME_PENNYFARTHING','FrolicBoat',\n",
    "                'SUBWAY_PLATFORM', 'SUBWAY_TRAIN', 'AIRPORT_HANGAR', 'AIRPORT_RUNWAY', 'Subway', 'Airport', 'FIRESTATION_FIRETRUCK',\n",
    "                      'FIRESTATION_FIREHELICOPTER', 'AIRPORT_PRIVATEJET', 'SUBWAY_SUBWAYPLATFORM', 'FIRESTATION_FIRESTATION']\n",
    "\n",
    "    recreational = ['RECREATIONGROUND_PLAYGROUND', 'RECREATIONGROUND_BACKYARD', 'RECREATIONGROUND_SKATEPARK', 'Playground', 'Swing', 'Slide',\n",
    "                     'Seesaw', 'Roundabout', 'JungleGym', 'Sandbox', 'Stegoslide', 'ClimbingFrame', 'PlaygroundFloor', 'MerryGoRound', 'SkatePark',\n",
    "                     'HelterSkelter', 'BigWheel_01', 'FAIRGROUND_MERRYGOROUND', 'RECREATIONGROUND_MINIGOLF', 'FAIRGROUND_HELTERSKELTER',\n",
    "                     'FAIRGROUND_BIGWHEEL','HOME_DRILL', 'Drill', 'Stadium', 'ShoppingMall', 'Park', 'Subway', 'SubwayPlatform', 'SubwayWashroom',\n",
    "                    'RECREATIONGROUND_FOUNTAIN',                     'SUBWAY_SUBWAYWASHROOM','NATIONALPARK_CAMPSITE', 'NATIONALPARK_WHEELCHAIRRAMP',\n",
    "                    'NATIONALPARK_SHELTER', 'NATIONALPARK_PICNICTABLE', 'NATIONALPARK_BENCH',\n",
    "                   'Restaurant', 'Shop', 'Store', 'Mall', 'NATIONALPARK_TREEHOUSE']\n",
    "\n",
    "    buildings = ['RESIDENTIALSMALL_BACKYARD', 'RESIDENTIAL_HOME', 'RESIDENTIAL_FRONTYARD', 'RESIDENTIAL_SMALL_HOUSE', 'RESIDENTIAL_TREEHOUSE',\n",
    "                    'House', 'Bungalow', 'Cottage', 'Mansion', 'ShoeHouse', 'DetachedHouse', 'TreeHouse', 'RESIDENTIALSMALL_BUNGALOW',\n",
    "                    'SUBURBIA_DETACHEDHOUSE', 'MANSION_FRONT', 'NATIONALPARK_SHOEHOUSE', 'NATIONALPARK_STORYBOOKHOUSE', 'RESIDENTIALSMALL_RACINGCAR']\n",
    "\n",
    "    special = ['ALIENBASE', 'TREASUREISLAND', 'SPACESTATION', 'MARS_MARSROVER', 'SPACEHATCH', 'AlienHatch', 'TreasureChest', 'BigStatue',\n",
    "                          'SpaceStation', 'AncientStatue', 'AncientHand', 'COUNTRYSIDE_TEMPLE', 'SEATEMPLE', 'DESERT_STEAMLOCOMOTIVE',\n",
    "                          'DESERT_ANCIENTSTATUE', 'DESERT_ANCIENTHAND', 'FAIRGROUND_FORTUNETELLERCARAVAN']\n",
    "\n",
    "    other = ['WASHABLE']\n",
    "\n",
    "    if task in vehicles:\n",
    "        return 'Vehicles'\n",
    "    elif task in recreational:\n",
    "        return 'Recreational'\n",
    "    elif task in buildings:\n",
    "        return 'Residential_Areas'\n",
    "    elif task in special:\n",
    "        return 'Special'\n",
    "    elif task in other:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Uncategorized'\n",
    "\n",
    "# Apply the categorization functions to create new columns\n",
    "train_data['CurrentTaskCategory'] = train_data['CurrentTask'].apply(categorize_current_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of CurrentTaskCategory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='CurrentTaskCategory')\n",
    "plt.title('Distribution of CurrentTaskCategory')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. CurrentSessionLength\n",
    "# plot the distribution of CurrentSessionLength\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=train_data, x='CurrentSessionLength', bins=10)\n",
    "plt.title('Distribution of CurrentSessionLength')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LastTaskCompleted\n",
    "# plot the distribution of LastTaskCompleted\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='LastTaskCompleted')\n",
    "plt.title('Distribution of LastTaskCompleted')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize LastTaskCompleted\n",
    "def categorize_last_task(task):\n",
    "    vehicles = ['WASH_VintageCar', 'WASH_Firetruck', 'WASH_Submarine', 'WASH_Boat', 'WASH_UFO', 'WASH_Motorbike', 'WASH_Plane',\n",
    "                'WASH_Helicopter', 'WASH_Train', 'WASH_Locomotive','WASH_PWVan', 'WASH_DirtBike', 'WASH_GolfCart', 'WASH_MotorbikeSidecar',\n",
    "                'WASH_80sRacingCar', 'WASH_FireTruck', 'WASH_CamperVan', 'WASH_PrivateJet', 'WASH_MarsRover',\n",
    "                'WASH_SUV', 'WASH_FireHelicopter', 'WASH_FortuneTellerCaravan', 'WASH_MonsterTruck', 'WASH_StuntPlane',\n",
    "                'WASH_SteamLocomotive', 'WASH_Marina_FishingBoat', 'WASH_Subway']\n",
    "\n",
    "    recreational = ['WASH_Playground', 'WASH_Swing', 'WASH_Slide', 'WASH_Seesaw', 'WASH_Roundabout',\n",
    "                    'WASH_JungleGym', 'WASH_Sandbox', 'WASH_Stegoslide', 'WASH_ClimbingFrame',\n",
    "                  'WASH_PlaygroundFloor', 'WASH_MerryGoRound', 'WASH_SkatePark', 'WASH_HelterSkelter',\n",
    "                    'WASH_BigWheel_01','WASH_Park', 'WASH_Garden', 'WASH_Backyard', 'WASH_Porch',\n",
    "                    'WASH_TreeHouse', 'WASH_Temple', 'WASH_SeaTemple', 'WASH_Fountain']\n",
    "\n",
    "    buildings = ['WASH_House', 'WASH_Bungalow', 'WASH_Cottage', 'WASH_Restaurant', 'WASH_Shop',\n",
    "                 'WASH_Store', 'WASH_Mall', 'WASH_Mansion', 'WASH_ShoeHouse', 'WASH_DetachedHouse',\n",
    "                 'WASH_FireStation', 'WASH_StoryBookCottage', 'WASH_Airport', 'WASH_Stadium', 'WASH_Park',\n",
    "                 'WASH_School', 'WASH_SubwayWashroom', 'WASH_SubwayPlatform']\n",
    "\n",
    "    furniture = ['WASH_Chair', 'WASH_Table', 'WASH_Bench', 'WASH_Sofa', 'WASH_Bench_01', 'WASH_Bench_02', 'WASH_Bin_01', 'WASH_Bin']\n",
    "\n",
    "    special = ['WASH_AlienHatch', 'WASH_TreasureChest', 'WASH_BigStatue', 'WASH_SpaceStation', 'WASH_AncientStatue',\n",
    "               'WASH_Drill', 'WASH_FrolicBoat', 'WASH_AncientHand']\n",
    "\n",
    "    other = ['WASHABLE']\n",
    "\n",
    "    if task in vehicles:\n",
    "        return 'Vehicles'\n",
    "    elif task in recreational:\n",
    "        return 'Playground'\n",
    "    elif task in buildings:\n",
    "        return 'Buildings'\n",
    "    elif task in furniture:\n",
    "        return 'Furniture'\n",
    "    elif task in special:\n",
    "        return 'Special'\n",
    "    elif task in other:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Uncategorized'\n",
    "    \n",
    "train_data['LastTaskCategory'] = train_data['LastTaskCompleted'].apply(categorize_last_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of LastTaskCategory\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='LastTaskCategory')\n",
    "plt.title('Distribution of LastTaskCategory')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. LevelProgressionAmount\n",
    "# plot the distribution of LevelProgressionAmount\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=train_data, x='LevelProgressionAmount', bins=10)\n",
    "plt.title('Distribution of LevelProgressionAmount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. QuestionType\n",
    "# plot the distribution of QuestionType\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_data, x='QuestionType')\n",
    "plt.title('Distribution of QuestionType')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. ResponseValue\n",
    "# plot the distribution of ResponseValue\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=train_data, x='ResponseValue', bins=10)\n",
    "plt.title('Distribution of ResponseValue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets again\n",
    "def import_data_from_csv():\n",
    "    df_train = pd.read_csv('train_data.csv')\n",
    "    df_test = pd.read_csv('test_data.csv')\n",
    "    return df_train, df_test\n",
    "train_data, test_data = import_data_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if fill missing values by deleting the rows with missing values\n",
    "train_data_1 = train_data.copy()\n",
    "train_data_1.dropna(inplace=True)\n",
    "train_data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if delete LastTaskCompleted and then delete the rows with missing values\n",
    "train_data_2 = train_data.copy()\n",
    "train_data_2.drop(columns=['LastTaskCompleted'], inplace=True)\n",
    "train_data_2.dropna(inplace=True)\n",
    "train_data_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = train_data_2['LevelProgressionAmount'].min()\n",
    "max_value = train_data_2['LevelProgressionAmount'].max()\n",
    "print(min_value)\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the percentile-based bin edges dynamically\n",
    "bin_edges = [0] + train_data_2['LevelProgressionAmount'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]).tolist() + [1.001]\n",
    "\n",
    "# Generate labels for each bin\n",
    "labels = [f\"from {bin_edges[i]} to {bin_edges[i+1]}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "# Create a new column with the binned values\n",
    "train_data_2['BinnedLevelProgression'] = pd.cut(train_data_2['LevelProgressionAmount'], bins=bin_edges, labels=labels, right=False)\n",
    "\n",
    "# Display the initial result\n",
    "print(\"Initial bin counts:\")\n",
    "print(train_data_2['BinnedLevelProgression'].value_counts())\n",
    "print(\"Number of missing values:\", train_data_2['BinnedLevelProgression'].isnull().sum())\n",
    "\n",
    "# Drop two instances from the bin 'from 0.9838766360000001 to 1.001'\n",
    "indices_to_drop_bin1 = train_data_2[train_data_2['BinnedLevelProgression'] == 'from 0.9838766360000001 to 1.001'].index[:2]\n",
    "train_data_2 = train_data_2.drop(indices_to_drop_bin1)\n",
    "\n",
    "# Drop three instances from the bin 'from 1.0 to 1.001'\n",
    "indices_to_drop_bin2 = train_data_2[train_data_2['BinnedLevelProgression'] == 'from 1.0 to 1.001'].index[:3]\n",
    "train_data_2 = train_data_2.drop(indices_to_drop_bin2)\n",
    "\n",
    "# Recreate the binned column\n",
    "train_data_2['BinnedLevelProgression'] = pd.cut(train_data_2['LevelProgressionAmount'], bins=bin_edges, labels=labels, right=False)\n",
    "\n",
    "# Display the adjusted result and sort by bin edges to maintain order\n",
    "print(\"Adjusted bin counts:\")\n",
    "print(train_data_2['BinnedLevelProgression'].value_counts().reindex(labels))\n",
    "print(\"Number of missing values:\", train_data_2['BinnedLevelProgression'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the percentile-based bin edges dynamically (because otherwise we will loose values due to floating points. Like this we're also making sure the distribution is normal)\n",
    "bin_edges = [0] + train_data_2['LevelProgressionAmount'].quantile([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]).tolist() + [1.001]\n",
    "\n",
    "# Generate labels for each bin\n",
    "labels = [f\"from {bin_edges[i]} to {bin_edges[i+1]}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "# Create a new column with the binned values\n",
    "train_data_2['BinnedLevelProgression'] = pd.cut(train_data_2['LevelProgressionAmount'], bins=bin_edges, labels=labels, right=False)\n",
    "\n",
    "# Display the result\n",
    "print(train_data_2['BinnedLevelProgression'].value_counts())\n",
    "print(\"Number of missing values:\", train_data_2['BinnedLevelProgression'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bin edges manually to ensure correct binning, including separate bins for 0.9838 to 1.0 and 1.0 to 1.001\n",
    "bin_edges = [0, 0.104285634, 0.213396196, 0.32048484899999996, 0.43458137200000005, 0.55007635, 0.662722016, 0.771927278, 0.87988618, 0.9838, 0.999999, 1.001]\n",
    "\n",
    "# Generate labels for each bin\n",
    "labels = [f\"from {bin_edges[i]} to {bin_edges[i+1]}\" for i in range(len(bin_edges)-1)]\n",
    "\n",
    "# Apply binning to the LevelProgressionAmount column in train_data\n",
    "train_data_2['BinnedLevelProgression'] = pd.cut(train_data_2['LevelProgressionAmount'], bins=bin_edges, labels=labels, right=False, include_lowest=True)\n",
    "# Display the result\n",
    "print(train_data_2['BinnedLevelProgression'].value_counts())\n",
    "print(\"Number of missing values in train_data:\", train_data_2['BinnedLevelProgression'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom mapping dictionary (this is because otherwise the bin \"from 0.9838766360000001 to 1.001\" would be labeled as 1)\n",
    "custom_mapping = {\n",
    "    \"from 0 to 0.104285634\": 0,\n",
    "    \"from 0.104285634 to 0.213396196\": 1,\n",
    "    \"from 0.213396196 to 0.32048484899999996\": 2,\n",
    "    \"from 0.32048484899999996 to 0.43458173200000005\": 3,\n",
    "    \"from 0.43458173200000005 to 0.55007635\": 4,\n",
    "    \"from 0.55007635 to 0.662272016\": 5,\n",
    "    \"from 0.662272016 to 0.771927278\": 6,\n",
    "    \"from 0.771927278 to 0.87988618\": 7,\n",
    "    \"from 0.104285634 to 0.213396196\": 8,\n",
    "    \"from 0.9838766360000001 to 1.001\": 9\n",
    "}\n",
    "\n",
    "# Initialize LabelEncoder with custom mapping\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.mapping = [{key: value} for key, value in custom_mapping.items()]\n",
    "\n",
    "# Fit and transform the column\n",
    "train_data_2['BinnedLevelProgression_encoded'] = label_encoder.fit_transform(train_data_2['BinnedLevelProgression'])\n",
    "\n",
    "# Display the result\n",
    "print(train_data_2['BinnedLevelProgression_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the binned values\n",
    "train_data_2['BinnedLevelProgression'] = pd.cut(train_data_2['LevelProgressionAmount'], bins=11, labels=False, right=False)\n",
    "\n",
    "# Display the result\n",
    "print(train_data_2['BinnedLevelProgression'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if fill missing values with mode for categorical features and mean for numerical features\n",
    "train_data_3 = train_data.copy()\n",
    "train_data_3['CurrentGameMode'].fillna(train_data_3['CurrentGameMode'].mode()[0], inplace=True)\n",
    "train_data_3['CurrentTask'].fillna(train_data_3['CurrentTask'].mode()[0], inplace=True)\n",
    "train_data_3['LastTaskCompleted'].fillna(train_data_3['LastTaskCompleted'].mode()[0], inplace=True)\n",
    "train_data_3['LevelProgressionAmount'].fillna(train_data_3['LevelProgressionAmount'].mean(), inplace=True)\n",
    "train_data_3.info()\n",
    "# check each feature\n",
    "print(train_data_3['CurrentGameMode'].value_counts())\n",
    "print(train_data_3['CurrentTask'].value_counts())\n",
    "print(train_data_3['LastTaskCompleted'].value_counts())\n",
    "print(train_data_3['LevelProgressionAmount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if fill missing values according to the meaning of the feature\n",
    "train_data_4 = train_data.copy()\n",
    "train_data_4['LastTaskCompleted'].fillna('Not_Saved', inplace=True)\n",
    "train_data_4['CurrentTask'].fillna('Not_Playing', inplace=True)\n",
    "train_data_4['LevelProgressionAmount'].fillna(0, inplace=True)\n",
    "\n",
    "train_data_4['LastTaskCompleted'].fillna('Not_Saved', inplace=True)\n",
    "train_data_4['CurrentTask'].fillna('Not_Playing', inplace=True)\n",
    "train_data_4['LevelProgressionAmount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from training data\n",
    "def remove_outliers(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "train_data_4 = remove_outliers(train_data_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "train_data['LastTaskCompleted'].fillna('Not_Saved', inplace=True)\n",
    "train_data['CurrentTask'].fillna('Not_Playing', inplace=True)\n",
    "train_data['LevelProgressionAmount'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from training data\n",
    "def remove_outliers(df):\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from the train_data\n",
    "train_data_no_outliers = remove_outliers(train_data)\n",
    "\n",
    "# Visualize the before and after for all numerical columns in train_data\n",
    "numerical_cols = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Before removing outliers\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=train_data, x=col)\n",
    "    plt.title(f'Boxplot of {col} (Before)')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data=train_data, x=col, bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col} (Before)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "     # After removing outliers\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(data=train_data_no_outliers, x=col)\n",
    "    plt.title(f'Boxplot of {col} (After)')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data=train_data_no_outliers, x=col, bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col} (After)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = remove_outliers(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'TimeUtc': According to feature \"TimeUtc\", we extract the date and time information and create two new features \"Day\" and \"Time\"\n",
    "# \"Day\" should be a categorical feature and include monday, tuesday, wednesday, thursday, friday, saturday, and sunday, and then it gets encoded\n",
    "# \"Time\" should be a categorical feature and include night, daytime, and evening, and then it gets encoded\n",
    "train_data['TimeUtc'] = pd.to_datetime(train_data['TimeUtc'])\n",
    "train_data['Day'] = train_data['TimeUtc'].dt.day_name()\n",
    "# train_data_1['Day'] = pd.Categorical(train_data_1['Day'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "train_data['Time'] = train_data['TimeUtc'].dt.hour\n",
    "train_data['Time'] = pd.cut(train_data['Time'], bins=[-1, 5, 17, 23], labels=['night', 'daytime', 'evening'])\n",
    "# encode 'Day': Monday=0, Tuesday=1, Wednesday=2, Thursday=3, Friday=4, Saturday=5, Sunday=6\n",
    "train_data['Day'] = train_data['Day'].map({'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6})\n",
    "train_data['Time'] = train_data['Time'].map({'night': 0, 'daytime': 1, 'evening': 2})\n",
    "# change 'Day' and 'Time' to int\n",
    "train_data['Day'] = train_data['Day'].astype(int)\n",
    "train_data['Time'] = train_data['Time'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['QuestionTiming', 'CurrentGameMode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the numerical feature\n",
    "scaler = StandardScaler()\n",
    "train_data[['Day', 'Time', 'CurrentSessionLength']] = scaler.fit_transform(train_data[['Day', 'Time', 'CurrentSessionLength']])\n",
    "train_data['StandardizedProgression'] = scaler.fit_transform(train_data[['LevelProgressionAmount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'UserID' and calculate statistical features for 'ResponseValue'\n",
    "user_stats = train_data.groupby('UserID')['ResponseValue'].agg(['mean', 'median', 'std']).reset_index()\n",
    "user_stats.columns = ['UserID', 'ResponseValue_mean', 'ResponseValue_median', 'ResponseValue_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the new features back into the original dataframe\n",
    "train_data = pd.merge(train_data, user_stats, on='UserID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['ResponseValue_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['UserID'] = train_data['UserID'].str.replace('p', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categorization to LastTaskCompleted and CurrentTask\n",
    "special_tasks = [\n",
    "    'MarsRover', 'MARS_MARSROVER', 'WASH_MarsRover', 'RECREATIONGROUND_MINIGOLF', 'SteamLocomotive',\n",
    "    'WASH_SteamLocomotive', 'DESERT_STEAMLOCOMOTIVE', 'WASH_Fountain','RECREATIONGROUND_FOUNTAIN'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_task(task):\n",
    "\n",
    "    if task == 'Not_Saved' or task == 'Not_Playing':\n",
    "        return 0\n",
    "    elif task in special_tasks:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['LastTaskCompleted_Category'] = train_data['LastTaskCompleted'].apply(categorize_task)\n",
    "train_data['CurrentTask_Category'] = train_data['CurrentTask'].apply(categorize_task)\n",
    "\n",
    "# Verify the results\n",
    "print(train_data[['LastTaskCompleted', 'CurrentTask', 'LastTaskCompleted_Category', 'CurrentTask_Category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'UserID' and calculate statistical features for 'CurrentSessionLength' and 'LevelProgressionAmount'\n",
    "CSLstats = train_data.groupby('UserID')['CurrentSessionLength'].agg(['mean', 'median', 'std', 'max']).reset_index()\n",
    "CSLstats.columns = ['UserID', 'CSL_mean', 'CSL_median', 'CSL_std', 'CSL_max']\n",
    "LPAstats = train_data.groupby('UserID')['LevelProgressionAmount'].agg(['mean', 'median', 'std', 'max']).reset_index()\n",
    "LPAstats.columns = ['UserID', 'LPA_mean', 'LPA_median', 'LPA_std', 'LPA_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the new features back into the original dataframe\n",
    "train_data = pd.merge(train_data, CSLstats, on='UserID', how='left')\n",
    "train_data = pd.merge(train_data, LPAstats, on='UserID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['CSL_std'].fillna(0, inplace=True)\n",
    "\n",
    "# Impute NaN values in ResponseValue_std with 0\n",
    "train_data['LPA_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['QuestionTiming', 'TimeUtc', 'CurrentGameMode', 'CurrentTask', 'LastTaskCompleted', 'QuestionType', 'LevelProgressionAmount',\n",
    "                   'LastTaskCategory','CurrentTask_Category', 'LastTaskCompleted_Category']\n",
    "train_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all features are numeric and handle any non-numeric data\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].dtype == 'object':\n",
    "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out ResponseValue with only one instance\n",
    "value_counts = train_data['ResponseValue'].value_counts()\n",
    "filtered_train_data = train_data[train_data['ResponseValue'].isin(value_counts[value_counts > 1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trainning data into features and target\n",
    "X_2 = train_data.drop(columns='ResponseValue')\n",
    "y_2 = train_data['ResponseValue']\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a random forest model\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_2, y_train_2)\n",
    "y_pred = rfr.predict(X_val_2)\n",
    "\n",
    "# Apply Permutation Feature Importance\n",
    "perm_importance = permutation_importance(rfr, X_val_2, y_val_2, n_repeats=10, random_state=42)\n",
    "\n",
    "# Print the results\n",
    "print(\"Feature importances:\")\n",
    "for i in perm_importance.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X_2.columns[i]:<30} {perm_importance.importances_mean[i]:.4f} +/- {perm_importance.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling & hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X_train and y_train into training and validation sets\n",
    "X_train_1, X_valid_1, y_train_1, y_valid_1 = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dummy Regressor\n",
    "dummy_regressor = DummyRegressor(strategy='mean')\n",
    "dummy_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = dummy_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the dummy model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Logistic Regression\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "logistic_regression.fit(X_train_1, y_train_1)\n",
    "y_pred = logistic_regression.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the logistic regression model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Random Forest Regressor\n",
    "random_forest_regressor = RandomForestRegressor(random_state=42)\n",
    "random_forest_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = random_forest_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the random forest model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=skf, scoring=scorer, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MAE: {best_score}')\n",
    "\n",
    "# Train the model with best parameters on the full training set\n",
    "best_rf = RandomForestRegressor(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = best_rf.predict(X_valid_1)\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_1, y_pred))\n",
    "\n",
    "print(f'MAE of the best RandomForest model: {mae}')\n",
    "print(f'RMSE of the best RandomForest model: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SVR\n",
    "svr = SVR()\n",
    "svr.fit(X_train_1, y_train_1)\n",
    "y_pred = svr.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the SVR model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LGBM Regressor\n",
    "lgbm_regressor = LGBMRegressor(random_state=42)\n",
    "lgbm_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = lgbm_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the LGBM model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, cv=skf, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MAE: {best_score}')\n",
    "\n",
    "# Train the model with best parameters on the full training set\n",
    "best_lgbm = LGBMRegressor(**best_params, random_state=42)\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = best_lgbm.predict(X_valid_1)\n",
    "\n",
    "# Calculate MAE and RMSE\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid_1, y_pred))\n",
    "\n",
    "print(f'MAE of the best LightGBM model: {mae}')\n",
    "print(f'RMSE of the best LightGBM model: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. XGB Regressor\n",
    "xgb_regressor = XGBRegressor(random_state=42)\n",
    "xgb_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = xgb_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the XGB model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Define the scoring metric\n",
    "scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=skf, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "# Fit Grid Search\n",
    "grid_search.fit(X_train_1, y_train_1)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = -grid_search.best_score_\n",
    "\n",
    "print(f'Best parameters: {best_params}')\n",
    "print(f'Best MAE: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. mlp Regressor\n",
    "mlp_regressor = MLPRegressor(random_state=42)\n",
    "mlp_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = mlp_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the MLP model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Gradient Boosting Regressor\n",
    "gradient_boosting_regressor = GradientBoostingRegressor(random_state=42)\n",
    "gradient_boosting_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = gradient_boosting_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the Gradient Boosting model: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the numerical features\n",
    "X_train_1 = scaler.fit_transform(X_train_1)\n",
    "X_valid_1 = scaler.transform(X_valid_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. SGD Regressor\n",
    "sgd_regressor = SGDRegressor(random_state=42)\n",
    "sgd_regressor.fit(X_train_1, y_train_1)\n",
    "y_pred = sgd_regressor.predict(X_valid_1)\n",
    "mae = mean_absolute_error(y_valid_1, y_pred)\n",
    "print(f'MAE of the SGD model: {mae}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
